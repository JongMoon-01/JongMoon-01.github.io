---
title: "2020년도 학술제"
date: 2020-10-28 02:23:00 +0900
categories: [Seminar]
tags: [TeamProject, ImageProcess, yolov2, ImageAugmentation]
---
# 1. Motivation for Participation
내가 지원할 수 있는 학교 범위내에서 순천향대학교 진학한 이유가 해당 학교는 학부생 대상으로 랩실에 가입하도록 권유하고 있기 때문이였다. 물론 2020년때 코로나때문에 학교에 못가 아무것도 알 수 없었지만 1학기 기말고사 당시 오프라인 시험을 보도록 규정되어있어 학교에 2틀정도 있었어야했는데 이때 천인국 교수님을 찾아뵈어서 랩장님 연락처를 받고 IPL랩실에 가입하게 되었다. 

## 2.1. Selection of Project Topic
주제는 데이터 + 인공지능 + 하드웨어가 당시 핫한 주제였어서 최대한 이쪽 분야와 겹치는 주제를 선택하도록 방향을 선정하였고 영상처리를 이용한 냉장고 관리 시스템이 선택되었습니다.
<center>
<img src="https://github.com/cisco/openh264/assets/56510688/7d85d79f-202c-45f3-bbd7-2f9dce6d1209" width="" height=""/>
<p><b>[그림1]. 주제 브레인스토밍</b></p>
</center>

<center>
<img src="https://github.com/cisco/openh264/assets/56510688/94f784de-59a6-4d4d-93c5-5237cab08da6" width="" height=""/>
<p><b>[그림1]. 영상처리를 이용한 냉장고 관리 시스템</b></p>
</center>

## 3.1. Role Sharing
당시에는 1학년 이였고 프로젝트 중간에 들어온 인력이여서 이미 파트는 랩실인원끼리 나뉘어져있었습니다. 저는 그중에 Deep Learning쪽에 관심이 많았어서 Deep Learning Part에서 yolov2실습하고 Labeling, Image Augmentation, Learning Model까지 맡아서 진행했습니다.

<center>
<img src="https://github.com/cisco/openh264/assets/56510688/e25e89fa-2064-4200-bdae-81dc22d400ac" width="" height=""/>
<p><b>[그림2]. 냉장고 관리 시스템 아키텍쳐</b></p>
</center>

## 3.2. My Task
### 3.2.1. Labeling
CNN 학습에는 여러 학습 방법이 있고 크게 2가지 정도로 분류 할 수 있습니다.
- 지도 학습(Supervised-Learning) : Input값으로 X data를 모델에 주면 Y data(Label)을 주어 학습시키는 방식입니다. Classification과 Regression Task를 처리할때 지도 학습을 많이 사용합니다.
- 비지도 학습(Un-Supervised-Learning) : Labeling되어있지 않은 데이터를 입력받아서 모델 스스로 데이터끼리의 패턴을 분석해 학습합니다. 대표적으로 Clustering Task가 있습니다.

해당 프로젝트에서는 Input값으로 음식물의 사진을 입력받고 Y값으로 해당 음식물의 사진이 무엇인지를 맞추는 Classfication문제이기 때문에 Labeling을 진행하였습니다. 사용 툴은 LabelImg를 사용했습니다.

<center>
<img src="https://github.com/cisco/openh264/assets/56510688/3a7a59eb-aba8-4ded-9dfb-56192f350b21" width="720" height=""/>
<p><b>[그림3]. LabelImg</b></p>
</center>

### 3.2.2. Data Preprocess
```
원본 이미지 : 460장
사용한 Augmentation Option : Togray, Rotate, Resized, HueSaturation, RandomResized, Flip
총 학습량 : 14,000장
```

<center>
<img src="https://github.com/cisco/openh264/assets/56510688/304c7316-a319-4aaf-979d-13e20bc81c62" width="720" height=""/>
<p><b>[그림4]. Image Augmentation Source Code(Albumentation)</b></p>
</center>

### 3.2.3. yolov4 Model
프로젝트에서는 yolov4 모델을 사용하게 되었습니다. 해당 모델은 20년 당시 Real-time Object Dectection분야에서 획기적인 성능과 처리속도를 보여줘서 선택했습니다. 이런 성능은 다른 모델과 차별화되는 Object Detection Flow에서 찾아볼 수 있습니다.
```flow
1. Split Image : S X S grid로 전체 이미지를 분할합니다.
2. Proposal Bounding Box : 분할된 Grid cell안에 특정 객체의 중심 커널(Feature)을 포함할 경우 해당 Cell에 대해 Proposal이 이루어집니다. 각 Grid cell은 B개의 BBox를 예측하고 각 Box에 대해 Confidence Score를 예측합니다.
3. Calculate Score per BBox and Output through size comparison with Threshold : Score는 해당 Box안에 Object가 있을 확률(T)이 어느정도 되는지 그리고 Object가 자신이 예측한 Oject가 맞을 확률(TT)이 얼마나 되는지에 대한 확률을 점수로 표현한 것입니다. 이를 수식으로 표현할 시 Pr(Class-i)*IOU(truthpred)가 됩니다.

 해당 수식은 Confidence Score가 IOU(=실제값과 예측박스의 교집합/실제값과 예측박스의 합집합)과 같기를 원합니다. 각 Grid Cell은 Pr(Class-i | Object)에 대해 조건부 확률 C도 예측합니다. "C는 Grid Cell안에 Object가 존재한다"는 전제하에 계산됩니다. 하지만 Yolo는 경계박스의 숫자 B와는 관련 없이 Grid Cell 당 한개의 Class set만 예측합니다.
  테스트 시간에 C와 Box각각의 Score값(각 Box에 대한 Class Score)를 곱하게 됩니다. 이 때 계산된 Score가 threshold 이상일 경우 출력값에 BBox가 출력됩니다.

 해당 식은 Pr(Class-i | Object)*Pr(Object)*IOU(truthpred)로 표현되고 조건부확률 공식에 의해 약분되면 Pr(Class-i ∩ Object)*IOU(truthpred)이 됩니다. 또한 U = Class-i ⊆ Object이므로 Pr(Class-i)*IOU(truthpred)로 다시 식이 대체됩니다.
 
 전체 예측값은 S*S*(B*5+C)Tensor로 encoding됩니다.
  - S : Number of Grid, B : Number of BBox, C : Number of Class, 5는 Classification nc가 5이기 때문에 상수입니다.
```
* Grid cell안에 Object가 없을 시 Confidence Score는 0입니다.
* Conditional Class Probabilities = Pr(Class-i | Object), 하나의 Grid Cell에 있는 Object가 어떤 Class에 속하는지 나타내는 값. BBox의 개수와는 상관없이 Grid Cell하나당 하나의 값을 가진다.
* Class specific confidence score =Pr(Class-i ∣ Object)∗Pr(Object)∗IOU(truthpred)=Pr(Class-i)∗IOU(truthpred)
* BBox가 예측하는 것 : 중앙의 (x,y)좌표, w, h, score

<center>
<img src="https://github.com/cisco/openh264/assets/56510688/7fa29751-aced-461e-9e4a-0ec0dc6d21d5" width="720" height=""/>
<p><b>[그림5]. Yolov4 Object Dectection Flow</b></p>
</center>

<center>
<img src="https://github.com/cisco/openh264/assets/56510688/d73c6fb2-db76-4486-a274-f422a0b6dfda" width="720" height=""/>
<p><b>[그림6]. IOU Calculation</b></p>
</center>

## 3.4  The result
원본 이미지에 대해 Augmentation을 진행하고 학습시켰을 때 Loss값 그래프가 확연히 좋아져서 혹시나 편향되어있는 모델이 아닌가 싶었지만 다행히도 실제 테스트를 진행했을때 영상입력에 대해 아주 좋은 성능을 보여주었습니다.

<center>
<img src="https://github.com/cisco/openh264/assets/56510688/6750ad6a-56d0-43b3-82f8-6ee826085de0" width="720" height=""/>
<p><b>[그림4]. 학습 결과, 학습 시간에 따른 LOSS Graph</b></p>
</center>

# 4.1 Seminar Review
대학생떄 처음으로 나가는 교내 대회이기도 하고 처음으로 하는 팀프로젝트여서 많이 힘들기도 하고 우여곡절이 많았지만 금상도 타고 마무리는 좋게 끝나서 다행이였던 경험이였습니다. 특히 혼자서 CNN공부할때 처음접하는 용어, 개념이 많아서 이해하기 정말 난해했었습니다. 결국에는 사이버네틱스 분야랑 장소야(receptive-field, 용어 틀렸을 수도 있습니다.)가 시각정보를 처리하는 과정을 이해해 CNN까지 이해할 수 있었습니다.